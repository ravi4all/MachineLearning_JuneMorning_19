{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, os\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'emails/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataFiles = []\n",
    "# for root, folder, files in os.walk(path):\n",
    "#     for file in files:\n",
    "#         dataFiles.append(root+'/'+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('emails/ham/00002.9c4069e25e1ef370c078db7ee85ff9ac')\n",
    "data = file.readlines()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = False\n",
    "d = []\n",
    "for line in data:\n",
    "    if line == \"\\n\":\n",
    "        body = True\n",
    "    if body:\n",
    "        d.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " 'Martin A posted:\\n',\n",
       " 'Tassos Papadopoulos, the Greek sculptor behind the plan, judged that the\\n',\n",
       " ' limestone of Mount Kerdylio, 70 miles east of Salonika and not far from the\\n',\n",
       " ' Mount Athos monastic community, was ideal for the patriotic sculpture. \\n',\n",
       " ' \\n',\n",
       " \" As well as Alexander's granite features, 240 ft high and 170 ft wide, a\\n\",\n",
       " ' museum, a restored amphitheatre and car park for admiring crowds are\\n',\n",
       " 'planned\\n',\n",
       " '---------------------\\n',\n",
       " 'So is this mountain limestone or granite?\\n',\n",
       " \"If it's limestone, it'll weather pretty fast.\\n\",\n",
       " '\\n',\n",
       " '------------------------ Yahoo! Groups Sponsor ---------------------~-->\\n',\n",
       " '4 DVDs Free +s&p Join Now\\n',\n",
       " 'http://us.click.yahoo.com/pt6YBB/NXiEAA/mG3HAA/7gSolB/TM\\n',\n",
       " '---------------------------------------------------------------------~->\\n',\n",
       " '\\n',\n",
       " 'To unsubscribe from this group, send an email to:\\n',\n",
       " 'forteana-unsubscribe@egroups.com\\n',\n",
       " '\\n',\n",
       " ' \\n',\n",
       " '\\n',\n",
       " 'Your use of Yahoo! Groups is subject to http://docs.yahoo.com/info/terms/ \\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path):\n",
    "    for root, folder, files in os.walk(path):\n",
    "        for file in files:\n",
    "            filename = root+'/'+file\n",
    "            file = io.open(filename,encoding='latin1')\n",
    "            body = False\n",
    "            data = []\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                if line == '\\n':\n",
    "                    body = True\n",
    "                if body:\n",
    "                    data.append(line)\n",
    "            file.close()\n",
    "            msg = '\\n'.join(data)\n",
    "            yield msg, filename\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df(path, classification):\n",
    "    rows = []\n",
    "    index = []\n",
    "    for message, filename in read_file(path):\n",
    "        rows.append({'message':message,'class':classification})\n",
    "        index.append(filename)\n",
    "        \n",
    "    return pd.DataFrame(data=rows, index=index)\n",
    "\n",
    "dataset = pd.DataFrame({'message':[], 'class':[]})\n",
    "dataset = dataset.append(df('emails/ham', 'ham'))\n",
    "dataset = dataset.append(df('emails/spam', 'spam'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>emails/ham/00001.7c53336b37003a9286aba55d2945844c</th>\n",
       "      <td>ham</td>\n",
       "      <td>\\n\\n    Date:        Wed, 21 Aug 2002 10:54:46...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emails/ham/00002.9c4069e25e1ef370c078db7ee85ff9ac</th>\n",
       "      <td>ham</td>\n",
       "      <td>\\n\\nMartin A posted:\\n\\nTassos Papadopoulos, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emails/ham/00003.860e3c3cee1b42ead714c5c874fe25f7</th>\n",
       "      <td>ham</td>\n",
       "      <td>\\n\\nMan Threatens Explosion In Moscow \\n\\n\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emails/ham/00004.864220c5b6930b209cc287c361c99af1</th>\n",
       "      <td>ham</td>\n",
       "      <td>\\n\\nKlez: The Virus That Won't Die\\n\\n \\n\\nAlr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emails/ham/00005.bf27cdeaf0b8c4647ecd61b1d09da613</th>\n",
       "      <td>ham</td>\n",
       "      <td>\\n\\n&gt;  in adding cream to spaghetti carbonara,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  class  \\\n",
       "emails/ham/00001.7c53336b37003a9286aba55d2945844c   ham   \n",
       "emails/ham/00002.9c4069e25e1ef370c078db7ee85ff9ac   ham   \n",
       "emails/ham/00003.860e3c3cee1b42ead714c5c874fe25f7   ham   \n",
       "emails/ham/00004.864220c5b6930b209cc287c361c99af1   ham   \n",
       "emails/ham/00005.bf27cdeaf0b8c4647ecd61b1d09da613   ham   \n",
       "\n",
       "                                                                                             message  \n",
       "emails/ham/00001.7c53336b37003a9286aba55d2945844c  \\n\\n    Date:        Wed, 21 Aug 2002 10:54:46...  \n",
       "emails/ham/00002.9c4069e25e1ef370c078db7ee85ff9ac  \\n\\nMartin A posted:\\n\\nTassos Papadopoulos, t...  \n",
       "emails/ham/00003.860e3c3cee1b42ead714c5c874fe25f7  \\n\\nMan Threatens Explosion In Moscow \\n\\n\\n\\n...  \n",
       "emails/ham/00004.864220c5b6930b209cc287c361c99af1  \\n\\nKlez: The Virus That Won't Die\\n\\n \\n\\nAlr...  \n",
       "emails/ham/00005.bf27cdeaf0b8c4647ecd61b1d09da613  \\n\\n>  in adding cream to spaghetti carbonara,...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize, punkt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = dataset['message'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# msg = re.findall('[\\w]+',msg)\n",
    "tokens = []\n",
    "for i in range(len(dataset)):\n",
    "    msg = re.findall('[\\w]+',dataset['message'][i])\n",
    "    tokens.append(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textProcessing(df):\n",
    "    tokens = []\n",
    "    for i in range(len(df)):\n",
    "#         tokens.append(word_tokenize(df['message'][i]))\n",
    "        msg = re.findall('[\\w]+',df['message'][i])\n",
    "        tokens.append(msg)\n",
    "\n",
    "    stopwordsList = stopwords.words(\"english\")\n",
    "#     stopwordsList.extend([',','.','-','!',':','>','<','\\n','@','#','']\n",
    "\n",
    "    wordsList = []\n",
    "    for tokenList in tokens:\n",
    "        words = []\n",
    "        for word in tokenList:\n",
    "            if word.lower() not in stopwordsList:\n",
    "                words.append(word.lower())\n",
    "        wordsList.append(words)\n",
    "\n",
    "    wnet = WordNetLemmatizer()\n",
    "    for i in range(len(wordsList)):\n",
    "        for j in range(len(wordsList[i])):\n",
    "            wordsList[i][j] = wnet.lemmatize(wordsList[i][j], pos='v')\n",
    "\n",
    "    for i in range(len(wordsList)):\n",
    "        wordsList[i] = ' '.join(wordsList[i])\n",
    "\n",
    "    return wordsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsList = textProcessing(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'martin post tassos papadopoulos greek sculptor behind plan judge limestone mount kerdylio 70 miles east salonika far mount athos monastic community ideal patriotic sculpture well alexander granite feature 240 ft high 170 ft wide museum restore amphitheatre car park admire crowd plan mountain limestone granite limestone weather pretty fast yahoo group sponsor 4 dvds free p join http us click yahoo com pt6ybb nxieaa mg3haa 7gsolb tm unsubscribe group send email forteana unsubscribe egroups com use yahoo group subject http docs yahoo com info term'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsList[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = cv.fit_transform(wordsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = vect.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(vect, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2250, 58388)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750, 58388)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2250,)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750,)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LogisticRegression()\n",
    "reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9866666666666667"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2 = nb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
